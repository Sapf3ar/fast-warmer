{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db393b7f-52b9-4ed5-8b2d-9ba7f5630a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import implicit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.cpu.als import AlternatingLeastSquares\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7426926e-066e-4e4b-ae9c-86802e0a33ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:36<00:00, 11.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user-author matrix: (32203, 23206)\n"
     ]
    }
   ],
   "source": [
    "video_stats = pl.read_parquet('data/video_stat.parquet')\n",
    "video_stats = video_stats.filter(pl.col(\"v_frac_avg_watchtime_30_day_duration\") > 0.00008)\n",
    "\n",
    "top_authors = (\n",
    "    video_stats\n",
    "    .group_by(\"author_id\")\n",
    "    .agg([\n",
    "        pl.col(\"video_id\").count().alias(\"video_count\")\n",
    "    ])\n",
    ")\n",
    "filtered_data = top_authors.filter(pl.col(\"video_count\") > 10)\n",
    "authors = np.unique(filtered_data[\"author_id\"])\n",
    "\n",
    "video_to_author = video_stats.select([\"video_id\", \"author_id\"]).to_dict(as_series=False)\n",
    "\n",
    "user_interaction_counts = []\n",
    "for log_path in tqdm(glob(\"data/logs*.parquet\")):\n",
    "    user_interaction_counts_i = {}\n",
    "    log = pl.read_parquet(log_path)\n",
    "\n",
    "    log_with_authors = log.join(\n",
    "        video_stats.select([\"video_id\", \"author_id\"]),\n",
    "        on=\"video_id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    log_filtered = log_with_authors.filter(pl.col(\"author_id\").is_in(authors))\n",
    "\n",
    "    for user_id in log_filtered[\"user_id\"]:\n",
    "        user_interaction_counts_i[user_id] = user_interaction_counts_i.get(user_id, 0) + 1\n",
    "\n",
    "    user_interaction_counts.append(user_interaction_counts_i)\n",
    "\n",
    "total_user_interaction_counts = {}\n",
    "for user_counts in tqdm(user_interaction_counts):\n",
    "    for user_id, count in user_counts.items():\n",
    "        if user_id in total_user_interaction_counts:\n",
    "            total_user_interaction_counts[user_id] += count\n",
    "        else:\n",
    "            total_user_interaction_counts[user_id] = count\n",
    "\n",
    "filtered_users = {user_id: count for user_id, count in total_user_interaction_counts.items() if count >= 100}\n",
    "\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "users_set = set()\n",
    "for log_path in tqdm(glob(\"data/logs*.parquet\")):\n",
    "    log = pl.read_parquet(log_path)\n",
    "\n",
    "    log_with_authors = log.join(\n",
    "        video_stats.select([\"video_id\", \"author_id\"]),\n",
    "        on=\"video_id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    log_filtered = log_with_authors.filter(pl.col(\"author_id\").is_in(authors))\n",
    "\n",
    "    user_ids = log_filtered[\"user_id\"].to_list()\n",
    "    author_ids = log_filtered[\"author_id\"].to_list()\n",
    "\n",
    "    for user_id, author_id in zip(user_ids, author_ids):\n",
    "        if user_id in filtered_users:\n",
    "            rows.append(user_id)\n",
    "            cols.append(author_id)\n",
    "\n",
    "filtered_users = sorted(filtered_users)\n",
    "user_to_idx = {user: idx for idx, user in enumerate(filtered_users)}\n",
    "author_to_idx = {author: idx for idx, author in enumerate(authors)}\n",
    "\n",
    "rows_idx = np.array([user_to_idx[user] for user in rows], dtype=np.int32)\n",
    "cols_idx = np.array([author_to_idx[author] for author in cols], dtype=np.int32)\n",
    "\n",
    "data = np.ones(len(rows_idx), dtype=np.int8)\n",
    "\n",
    "user_author_matrix = csr_matrix((data, (rows_idx, cols_idx)), shape=(len(filtered_users), len(authors)))\n",
    "\n",
    "print(\"Shape of user-author matrix:\", user_author_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1447d-14b3-4526-abc7-11c4ab03e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def get_similar_items(model, item_idx: int, n: int = 5):\n",
    "    \"\"\"\n",
    "    Возвращает список похожих объектов для заданного item.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        Тренированная модель рекомендаций.\n",
    "    item_idx : int\n",
    "        Идентификатор объекта.\n",
    "    n : int, optional\n",
    "        Количество похожих объектов (default is 5).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Список похожих объектов.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        similar_items = model.similar_items(item_idx, N=n)\n",
    "        return [item for item in similar_items[0]]\n",
    "    except:\n",
    "        print(item_idx)\n",
    "        return [0]\n",
    "\n",
    "\n",
    "def calculate_item_metrics(test_matrix, model, n_recommendations: int = 100):\n",
    "    \"\"\"\n",
    "    Подсчет метрик качества рекомендаций на основе похожих объектов (авторов): precision, recall, F1, MAP.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_matrix : csr_matrix\n",
    "        Тестовая матрица взаимодействий объектов (авторов).\n",
    "    model : object\n",
    "        Тренированная модель рекомендаций.\n",
    "    n_recommendations : int, optional\n",
    "        Количество рекомендаций для каждого объекта (default is 5).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Значения метрик (precision, recall, f1, map_score).\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    map_scores = []\n",
    "    \n",
    "    # Пройдемся по всем объектам (авторам) в тестовой матрице\n",
    "    for item_id in tqdm(range(test_matrix.shape[1])):\n",
    "        # Получаем реальные объекты (авторов), с которыми объект связан в тестовой выборке\n",
    "        true_items = test_matrix[item_id].nonzero()[1]\n",
    "\n",
    "        if len(true_items) == 0:\n",
    "            continue\n",
    "\n",
    "        # Получаем рекомендации похожих объектов (авторов)\n",
    "        recommended_items = get_similar_items(model, item_id, n=n_recommendations)\n",
    "\n",
    "        # Пересечение рекомендованных объектов с теми, с которыми объект действительно взаимодействовал\n",
    "        hits = len(set(recommended_items) & set(true_items))\n",
    "\n",
    "        # Precision@N\n",
    "        precision_at_n = hits / len(recommended_items) if len(recommended_items) > 0 else 0\n",
    "        precisions.append(precision_at_n)\n",
    "\n",
    "        # # Recall@N\n",
    "        # recall_at_n = hits / len(true_items) if len(true_items) > 0 else 0\n",
    "        # recalls.append(recall_at_n)\n",
    "\n",
    "        # Mean Average Precision (MAP)\n",
    "        relevant_flags = [1 if item in true_items else 0 for item in recommended_items]\n",
    "        if np.sum(relevant_flags) > 0:\n",
    "            map_scores.append(average_precision_score(relevant_flags, relevant_flags))\n",
    "        else:\n",
    "            map_scores.append(0)\n",
    "\n",
    "        # print(hits)\n",
    "        # break\n",
    "\n",
    "    # # Средние значения по всем объектам\n",
    "    precision = np.mean(precisions)\n",
    "    # recall = np.mean(recalls)\n",
    "    # f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    map_score = np.mean(map_scores) if len(map_scores) > 0 else 0\n",
    "    \n",
    "    return precision, map_score\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "model = AlternatingLeastSquares(factors=128, regularization=0.1, iterations=50)\n",
    "model.fit(user_author_matrix)  # Здесь обучающая матрица авторов и объектов (например, каналы и их авторы)\n",
    "# model = AlternatingLeastSquares().load(\"ALS\")\n",
    "\n",
    "precision, map_score = calculate_item_metrics(user_author_matrix, model)\n",
    "\n",
    "print(f\"Precision @ 100: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f20b1ecf-14a8-44b5-bf39-4b7e6283f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from typing import Optional, List\n",
    "from implicit.cpu.als import AlternatingLeastSquares\n",
    "\n",
    "\n",
    "class ALS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        authors_ids_path: str,\n",
    "        video_stats_path: str,\n",
    "        num_close_videos: int\n",
    "    ) -> None:\n",
    "        \"\"\"Инициализация модели ALS, загрузка данных по авторам и статистике видео\"\"\"\n",
    "        self.model = AlternatingLeastSquares().load(model_path)\n",
    "\n",
    "        self.video_stats = pl.read_parquet(video_stats_path)\n",
    "        self.num_close_videos = num_close_videos\n",
    "        self.num_close_authors = num_close_videos // 2\n",
    "\n",
    "        with open(authors_ids_path, \"r\") as f:\n",
    "            self.authors_to_idxs = json.load(f)\n",
    "        ids_to_autors = {}\n",
    "        for k,v in self.authors_to_idxs.items():\n",
    "            ids_to_autors[v] = k\n",
    "        self.ids_to_autors = ids_to_autors\n",
    "\n",
    "    def __getitem__(self, author_id: int) -> Optional[list[int]]:\n",
    "        \"\"\"Возвращает список рекомендованных видео для похожих авторов\"\"\"\n",
    "        if author_id not in self.authors_to_idxs:\n",
    "            return None\n",
    "\n",
    "        author_idx = self.authors_to_idxs[author_id]\n",
    "\n",
    "        # Получаем похожих авторов через ALS модель\n",
    "        similar_author_idxs = self.model.similar_items(author_idx, N=self.num_close_authors)[0]\n",
    "\n",
    "        similar_author_ids = []\n",
    "        for similar_author_idx in similar_author_idxs:\n",
    "            similar_author_ids.append(self.ids_to_autors[similar_author_idx])\n",
    "    \n",
    "        # Фильтруем видео по списку похожих авторов\n",
    "        close_author_videos = self.video_stats.filter(\n",
    "            pl.col(\"author_id\").is_in(similar_author_ids)\n",
    "        )\n",
    "\n",
    "        # Получаем рекомендованные видео с использованием взвешенного семплера\n",
    "        recommended_video_ids = get_top_videos(close_author_videos, n_top=2)\n",
    "\n",
    "        # Возвращаем список video_id\n",
    "        return recommended_video_ids\n",
    "\n",
    "\n",
    "def get_top_videos(data, n_top):\n",
    "    top_videos = (\n",
    "        data\n",
    "        .sort(\"v_likes\", descending=True)\n",
    "        .group_by(\"author_id\")\n",
    "        .head(n_top)\n",
    "    )\n",
    "    return top_videos[\"video_id\"].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b81baa-50d4-4574-aa95-da236b02563e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
